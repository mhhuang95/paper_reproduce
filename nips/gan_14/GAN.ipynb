{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# Training Params\n",
    "num_steps = 70000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Network Params\n",
    "image_dim = 784 # 28*28 pixels\n",
    "hidden_gen = 256\n",
    "hidden_dis = 256\n",
    "noise_dim = 100 # Noise data points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'gen_w1': tf.get_variable('gen_w1', shape=[noise_dim, hidden_gen], dtype=tf.float32, \n",
    "                             initializer = tf.random_normal_initializer(stddev=1. / tf.sqrt(noise_dim/ 2.))),\n",
    "    'gen_w_out': tf.get_variable('gen_w_out', shape=[ hidden_gen, image_dim], dtype=tf.float32, \n",
    "                             initializer = tf.random_normal_initializer(stddev=1. / tf.sqrt(hidden_gen / 2.))),\n",
    "    'dis_w1' : tf.get_variable('dis_w1', shape=[image_dim, hidden_dis], dtype=tf.float32, \n",
    "                             initializer = tf.random_normal_initializer(stddev=1. / tf.sqrt(image_dim/ 2.))),\n",
    "    'dis_w_out' : tf.get_variable('dis_w_out', shape=[ hidden_dis, 1], dtype=tf.float32, \n",
    "                             initializer = tf.random_normal_initializer(stddev=1. / tf.sqrt( hidden_dis / 2.)))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'gen_b1': tf.get_variable('gen_b1', shape=[hidden_gen], dtype=tf.float32, \n",
    "                             initializer = tf.zeros_initializer()),\n",
    "    'gen_b_out': tf.get_variable('gen_b_out', shape=[image_dim], dtype=tf.float32, \n",
    "                             initializer = tf.zeros_initializer()),\n",
    "    'dis_b1' : tf.get_variable('dis_b1', shape=[hidden_dis], dtype=tf.float32, \n",
    "                             initializer = tf.zeros_initializer()),\n",
    "    'dis_b_out' : tf.get_variable('dis_b_out', shape=[1], dtype=tf.float32, \n",
    "                             initializer = tf.zeros_initializer())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "def generator(x, weights, biases):\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, weights['gen_w1']) + biases['gen_b1'])\n",
    "    output = tf.nn.sigmoid(tf.matmul(layer1, weights['gen_w_out']) +  biases['gen_b_out'])\n",
    "    return output\n",
    "\n",
    "def discriminator(x, weights, biases):\n",
    "    layer1 = tf.nn.relu(tf.matmul(x, weights['dis_w1']) + biases['dis_b1'])\n",
    "    output = tf.nn.sigmoid(tf.matmul(layer1, weights['dis_w_out']) +  biases['dis_b_out'])\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# Build Networks\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "dis_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='dis_input')\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(gen_input, weights, biases)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "dis_real = discriminator(dis_input, weights, biases)\n",
    "dis_fake = discriminator(gen_sample, weights, biases)\n",
    "\n",
    "# Build Loss\n",
    "gen_loss = -tf.reduce_mean(tf.log(dis_fake))\n",
    "dis_loss = -tf.reduce_mean(tf.log(dis_real) + tf.log(1. - dis_fake))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_dis = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = [weights['gen_w1'], weights['gen_w_out'],\n",
    "            biases['gen_b1'], biases['gen_b_out']]\n",
    "# Discriminator Network Variables\n",
    "dis_vars = [weights['dis_w1'], weights['dis_w_out'],\n",
    "            biases['dis_b1'], biases['dis_b_out']]\n",
    "\n",
    "# Create training operations\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_dis = optimizer_disc.minimize(dis_loss, var_list=dis_vars)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generator Loss: 0.432765, Discriminator Loss: 1.652939\n",
      "Step 2000: Generator Loss: 4.691989, Discriminator Loss: 0.040894\n",
      "Step 4000: Generator Loss: 4.134645, Discriminator Loss: 0.073377\n",
      "Step 6000: Generator Loss: 3.682271, Discriminator Loss: 0.088773\n",
      "Step 8000: Generator Loss: 3.971675, Discriminator Loss: 0.174340\n",
      "Step 10000: Generator Loss: 3.395542, Discriminator Loss: 0.290145\n",
      "Step 12000: Generator Loss: 3.707896, Discriminator Loss: 0.172865\n",
      "Step 14000: Generator Loss: 3.817673, Discriminator Loss: 0.304770\n",
      "Step 16000: Generator Loss: 3.993147, Discriminator Loss: 0.177676\n",
      "Step 18000: Generator Loss: 2.653086, Discriminator Loss: 0.387295\n",
      "Step 20000: Generator Loss: 3.337434, Discriminator Loss: 0.285236\n",
      "Step 22000: Generator Loss: 3.871713, Discriminator Loss: 0.243435\n",
      "Step 24000: Generator Loss: 3.855072, Discriminator Loss: 0.315047\n",
      "Step 26000: Generator Loss: 3.496747, Discriminator Loss: 0.427379\n",
      "Step 28000: Generator Loss: 3.756812, Discriminator Loss: 0.249019\n",
      "Step 30000: Generator Loss: 3.336003, Discriminator Loss: 0.261895\n",
      "Step 32000: Generator Loss: 3.591566, Discriminator Loss: 0.427887\n",
      "Step 34000: Generator Loss: 3.640704, Discriminator Loss: 0.459301\n",
      "Step 36000: Generator Loss: 2.995005, Discriminator Loss: 0.411046\n",
      "Step 38000: Generator Loss: 2.991987, Discriminator Loss: 0.339308\n",
      "Step 40000: Generator Loss: 2.828702, Discriminator Loss: 0.340687\n",
      "Step 42000: Generator Loss: 2.893820, Discriminator Loss: 0.449492\n",
      "Step 44000: Generator Loss: 2.690794, Discriminator Loss: 0.361912\n",
      "Step 46000: Generator Loss: 3.078315, Discriminator Loss: 0.370077\n",
      "Step 48000: Generator Loss: 3.156024, Discriminator Loss: 0.439076\n",
      "Step 50000: Generator Loss: 2.558253, Discriminator Loss: 0.632253\n",
      "Step 52000: Generator Loss: 3.093521, Discriminator Loss: 0.368355\n",
      "Step 54000: Generator Loss: 2.857536, Discriminator Loss: 0.434669\n",
      "Step 56000: Generator Loss: 2.989160, Discriminator Loss: 0.384883\n",
      "Step 58000: Generator Loss: 2.735381, Discriminator Loss: 0.469934\n",
      "Step 60000: Generator Loss: 2.999016, Discriminator Loss: 0.324774\n",
      "Step 62000: Generator Loss: 2.683004, Discriminator Loss: 0.553750\n",
      "Step 64000: Generator Loss: 3.156308, Discriminator Loss: 0.417714\n",
      "Step 66000: Generator Loss: nan, Discriminator Loss: nan\n",
      "Step 68000: Generator Loss: nan, Discriminator Loss: nan\n",
      "Step 70000: Generator Loss: nan, Discriminator Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {dis_input: batch_x, gen_input: z}\n",
    "    _, _, gl, dl = sess.run([train_gen, train_dis, gen_loss, dis_loss],\n",
    "                            feed_dict=feed_dict)\n",
    "    if i % 2000 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 6\n",
    "canvas = np.empty((28*n, 28*n))\n",
    "\n",
    "for i in range(n):\n",
    "    z = np.random.uniform(-1., 1, [n, noise_dim])\n",
    "    \n",
    "    g = sess.run(gen_sample, feed_dict={gen_input: z})\n",
    "    \n",
    "    g = -1 * (g-1)\n",
    "    \n",
    "    for j in range(n):\n",
    "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
